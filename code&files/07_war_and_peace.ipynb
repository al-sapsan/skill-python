{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07aa4636-8180-4078-b0ed-a67c8f702eab",
   "metadata": {},
   "source": [
    "# Задача 7. «Война и мир»\n",
    "_ _ _"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7e67f-2cdf-46a9-8987-107d27937468",
   "metadata": {},
   "source": [
    "Для решения задачи подсчета статистики символов и поиска предложений с упоминанием имени \"Андрей\" в тексте романа Льва Толстого \"Война и мир\", можно использовать несколько различных подходов на Python. Рассмотрим три варианта реализации.\n",
    "\n",
    "## Вариант 1: Простой подсчет и разбиение на предложения\n",
    "\n",
    "### Описание алгоритма:\n",
    "Этот вариант основан на использовании встроенных методов Python. Мы будем читать весь текст файла, затем использовать цикл для подсчета количества каждого символа. Для поиска предложений с именем \"Андрей\" используем метод `split()`, который разбивает текст на предложения.\n",
    "\n",
    "### Код:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88545720-c73a-49fd-a3a9-8724cb40838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_char_frequency(text):\n",
    "    char_count = {}\n",
    "    total_chars = 0\n",
    "\n",
    "    for char in text:\n",
    "        if char in char_count:\n",
    "            char_count[char] += 1\n",
    "        else:\n",
    "            char_count[char] = 1\n",
    "        total_chars += 1\n",
    "\n",
    "    char_frequency = {char: count / total_chars for char, count in char_count.items()}\n",
    "    return char_frequency\n",
    "\n",
    "def find_sentences_with_name(text, name, limit=10):\n",
    "    sentences = text.split('. ')\n",
    "    result = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if any(name_form in sentence for name_form in [\"Андрей\", \"Андрея\", \"Андрею\", \"Андреем\", \"Андрее\"]):\n",
    "            result.append(sentence.strip() + '.')\n",
    "        if len(result) == limit:\n",
    "            break\n",
    "            \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    with open('war_and_peace.txt', 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Статистика символов\n",
    "    char_frequency = calculate_char_frequency(text)\n",
    "    print(\"Статистика:\")\n",
    "    for char, freq in sorted(char_frequency.items(), key=lambda x: -x[1])[:5]:\n",
    "        print(f\"{char} : {freq:.2f}\")\n",
    "    \n",
    "    # Поиск предложений\n",
    "    sentences = find_sentences_with_name(text, \"Андрей\")\n",
    "    print(\"\\nПредложения со словом «Андрей»:\")\n",
    "    for sentence in sentences:\n",
    "        print(sentence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c7c39-c59a-4899-ac5e-7cccd66612a4",
   "metadata": {},
   "source": [
    "### Скорость:\n",
    "- **Время работы:** \\(O(n)\\), где \\( n \\) — количество символов в тексте.\n",
    "- **Преимущества:** Простота реализации, использование базовых методов Python.\n",
    "- **Недостатки:** Ограниченные возможности оптимизации и управения данными.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e45e86-3957-4735-9089-6b5ca733a361",
   "metadata": {},
   "source": [
    "_ _ _\n",
    "## Вариант 2: Использование библиотеки `collections`\n",
    "\n",
    "### Описание алгоритма:\n",
    "Здесь мы используем библиотеку `collections`, в частности `Counter`, для более эффективного подсчета символов. Разбиение на предложения и поиск имени выполняются аналогично первому варианту.\n",
    "\n",
    "### Код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf95bd-a8a2-42f8-b1d8-3bac8913d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_char_frequency(text):\n",
    "    char_count = Counter(text)\n",
    "    total_chars = sum(char_count.values())\n",
    "    char_frequency = {char: count / total_chars for char, count in char_count.items()}\n",
    "    return char_frequency\n",
    "\n",
    "def find_sentences_with_name(text, name, limit=10):\n",
    "    sentences = text.split('. ')\n",
    "    result = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if any(name_form in sentence for name_form in [\"Андрей\", \"Андрея\", \"Андрею\", \"Андреем\", \"Андрее\"]):\n",
    "            result.append(sentence.strip() + '.')\n",
    "        if len(result) == limit:\n",
    "            break\n",
    "            \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    with open('war_and_peace.txt', 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Статистика символов\n",
    "    char_frequency = calculate_char_frequency(text)\n",
    "    print(\"Статистика:\")\n",
    "    for char, freq in sorted(char_frequency.items(), key=lambda x: -x[1])[:5]:\n",
    "        print(f\"{char} : {freq:.2f}\")\n",
    "    \n",
    "    # Поиск предложений\n",
    "    sentences = find_sentences_with_name(text, \"Андрей\")\n",
    "    print(\"\\nПредложения со словом «Андрей»:\")\n",
    "    for sentence in sentences:\n",
    "        print(sentence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4044fa23-b82d-4ec2-97f3-b274f15078cf",
   "metadata": {},
   "source": [
    "### Скорость:\n",
    "- **Время работы:** \\(O(n)\\), где \\( n \\) — количество символов в тексте.\n",
    "- **Преимущества:** Более эффективный подсчет символов за счет использования `Counter`, простота кода.\n",
    "- **Недостатки:** Малая разница в производительности по сравнению с первым вариантом, хотя код становится более лаконичным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e864af-7f57-4fcd-b404-ce36083fbf38",
   "metadata": {},
   "source": [
    "_ _ _\n",
    "## Вариант 3: Использование регулярных выражений для поиска предложений\n",
    "\n",
    "### Описание алгоритма:\n",
    "В этом варианте мы используем регулярные выражения для поиска предложений с именем \"Андрей\". Регулярные выражения позволяют более гибко управлять поиском текста и работать с более сложными шаблонами.\n",
    "\n",
    "### Код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba55ce-ac60-4a9a-90ab-2589f31366da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_char_frequency(text):\n",
    "    char_count = Counter(text)\n",
    "    total_chars = sum(char_count.values())\n",
    "    char_frequency = {char: count / total_chars for char, count in char_count.items()}\n",
    "    return char_frequency\n",
    "\n",
    "def find_sentences_with_name(text, name, limit=10):\n",
    "    pattern = r\"[^.]*\\b(?:Андрей|Андрея|Андрею|Андреем|Андрее)\\b[^.]*\\.\"\n",
    "    sentences = re.findall(pattern, text)\n",
    "    return sentences[:limit]\n",
    "\n",
    "def main():\n",
    "    with open('war_and_peace.txt', 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Статистика символов\n",
    "    char_frequency = calculate_char_frequency(text)\n",
    "    print(\"Статистика:\")\n",
    "    for char, freq in sorted(char_frequency.items(), key=lambda x: -x[1])[:5]:\n",
    "        print(f\"{char} : {freq:.2f}\")\n",
    "    \n",
    "    # Поиск предложений\n",
    "    sentences = find_sentences_with_name(text, \"Андрей\")\n",
    "    print(\"\\nПредложения со словом «Андрей»:\")\n",
    "    for sentence in sentences:\n",
    "        print(sentence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b710ae-64cc-45e6-8d68-fa67e317d10a",
   "metadata": {},
   "source": [
    "### Скорость:\n",
    "- **Время работы:** \\(O(n)\\) для подсчета символов, \\(O(m)\\) для поиска предложений, где \\( m \\) — количество предложений в тексте.\n",
    "- **Преимущества:** Регулярные выражения позволяют точно находить предложения с нужными словами, гибкость и мощность поиска.\n",
    "- **Недостатки:** Более сложный синтаксис регулярных выражений может усложнять код.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64bb5d9-1251-461a-addb-5dfa999b3e77",
   "metadata": {},
   "source": [
    "_ _ _\n",
    "## Заключение:\n",
    "\n",
    "1. **Простой подсчет и разбиение на предложения**:\n",
    "   - **Плюсы:** Очень простой и понятный код.\n",
    "   - **Минусы:** Потенциально менее эффективный, чем использование специальных инструментов.\n",
    "\n",
    "2. **Использование `collections.Counter`**:\n",
    "   - **Плюсы:** Более эффективный подсчет символов, чем в первом варианте.\n",
    "   - **Минусы:** Производительность сопоставима с первым вариантом.\n",
    "\n",
    "3. **Использование регулярных выражений**:\n",
    "   - **Плюсы:** Точный и мощный поиск предложений с определенными условиями.\n",
    "   - **Минусы:** Код становится более сложным из-за использования регулярных выражений.\n",
    "\n",
    "Выбор подходящего варианта зависит от конкретных требований к проекту и предпочтений разработчика."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece5c1a-6567-426a-9e24-723a0b81c68c",
   "metadata": {},
   "source": [
    "_ _ _\n",
    "Для решения задачи анализа текста и поиска предложений с упоминанием имени \"Андрей\", помимо уже рассмотренных методов, можно использовать и другие подходы и алгоритмы. Вот некоторые из них:\n",
    "\n",
    "## 1. **Алгоритмы поиска подстроки (например, KMP или Бойера-Мура)**\n",
    "\n",
    "**Описание:**  \n",
    "Вместо того чтобы искать предложения с именем \"Андрей\" с использованием регулярных выражений или простого поиска, можно использовать алгоритмы поиска подстроки, такие как алгоритм Кнута-Морриса-Пратта (KMP) или алгоритм Бойера-Мура. Эти алгоритмы оптимизированы для поиска подстрок и могут быть эффективнее при обработке больших текстов.\n",
    "\n",
    "**Как использовать:**\n",
    "- Разбиваем текст на предложения.\n",
    "- Применяем алгоритм KMP или Бойера-Мура для поиска имени \"Андрей\" и его форм в каждом предложении.\n",
    "- Если найдено совпадение, добавляем предложение в результаты.\n",
    "\n",
    "**Преимущества:**\n",
    "- Эффективный поиск подстрок с линейной сложностью \\(O(n + m)\\), где \\(n\\) — длина строки, а \\(m\\) — длина подстроки.\n",
    "- Позволяет быстро находить все вхождения заданного слова или фразы в больших текстах.\n",
    "\n",
    "**Недостатки:**\n",
    "- Сложность реализации по сравнению с встроенными методами Python.\n",
    "- Требует разбора текста на предложения перед применением алгоритма.\n",
    "\n",
    "## 2. **Использование `nltk` для обработки текста**\n",
    "\n",
    "**Описание:**  \n",
    "Библиотека Natural Language Toolkit (nltk) предоставляет мощные инструменты для обработки естественного языка. Можно использовать её для точного разбиения текста на предложения и анализа частоты символов.\n",
    "\n",
    "**Как использовать:**\n",
    "- Используем `nltk.sent_tokenize` для разбиения текста на предложения, что дает более точный результат, особенно в сложных текстах с аббревиатурами и сокращениями.\n",
    "- Используем `nltk.FreqDist` для подсчета частоты символов или слов в тексте.\n",
    "\n",
    "**Преимущества:**\n",
    "- Более точное разбиение на предложения, особенно в текстах со сложными структурами.\n",
    "- Возможность использовать дополнительные функции `nltk` для расширенного анализа текста.\n",
    "\n",
    "**Недостатки:**\n",
    "- Требуется установка и настройка библиотеки `nltk`.\n",
    "- Может быть медленнее по сравнению с базовыми методами, особенно на больших объемах данных.\n",
    "\n",
    "## 3. **Использование `pandas` для обработки и анализа текста**\n",
    "\n",
    "**Описание:**  \n",
    "Хотя `pandas` обычно используется для работы с табличными данными, его можно использовать и для анализа текста. Можно представить текст как серию строк и применить мощные функции `pandas` для поиска и фильтрации предложений.\n",
    "\n",
    "**Как использовать:**\n",
    "- Читаем текст в DataFrame, где каждая строка — это предложение.\n",
    "- Применяем функции `str.contains()` для поиска предложений, содержащих имя \"Андрей\".\n",
    "- Используем методы агрегирования и фильтрации для получения частотности символов.\n",
    "\n",
    "**Преимущества:**\n",
    "- Легкость обработки и фильтрации данных, особенно для больших объемов текста.\n",
    "- Возможность использовать весь арсенал функций `pandas` для анализа и визуализации данных.\n",
    "\n",
    "**Недостатки:**\n",
    "- Требуется понимание работы с DataFrame.\n",
    "- Более высокая потребность в памяти по сравнению с чистым Python.\n",
    "\n",
    "## 4. **Алгоритмы на основе структур данных: Trie и Suffix Tree**\n",
    "\n",
    "**Описание:**  \n",
    "Структуры данных, такие как Trie или суффиксное дерево (Suffix Tree), могут быть использованы для эффективного поиска подстрок в тексте.\n",
    "\n",
    "**Как использовать:**\n",
    "- Построение Trie или суффиксного дерева для всего текста или предложений.\n",
    "- Поиск всех предложений, содержащих нужные формы имени \"Андрей\", путем навигации по дереву.\n",
    "\n",
    "**Преимущества:**\n",
    "- Очень быстрый поиск подстрок после построения структуры данных.\n",
    "- Подходит для задач с многократным поиском подстрок в одном и том же тексте.\n",
    "\n",
    "**Недостатки:**\n",
    "- Сложность реализации и понимания.\n",
    "- Высокие требования к памяти, особенно для больших текстов.\n",
    "\n",
    "## 5. **Использование языковой модели (например, BERT или GPT) для контекстного поиска**\n",
    "\n",
    "**Описание:**  \n",
    "Можно использовать предварительно обученные языковые модели, такие как BERT или GPT, для поиска контекста, в котором упоминается имя \"Андрей\". Это позволит находить предложения с учетом контекста и тонких нюансов языка.\n",
    "\n",
    "**Как использовать:**\n",
    "- Загружаем предобученную модель.\n",
    "- Применяем модель для поиска предложений, содержащих имя \"Андрей\" в заданном контексте.\n",
    "- Анализируем найденные предложения на предмет соответствия заданным критериям.\n",
    "\n",
    "**Преимущества:**\n",
    "- Высокая точность поиска с учетом контекста.\n",
    "- Способность учитывать сложные формы и варианты использования слова в предложении.\n",
    "\n",
    "**Недостатки:**\n",
    "- Высокие вычислительные затраты.\n",
    "- Требуется понимание работы с языковыми моделями и библиотеками, такими как `transformers`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f0ee3-2330-46da-88a0-a587715cc132",
   "metadata": {},
   "source": [
    "_ _ _\n",
    "## Заключение\n",
    "\n",
    "В зависимости от конкретной задачи и требований, можно выбрать подходящий алгоритм или метод:\n",
    "\n",
    "1. **Для простоты и быстроты разработки:** Подходы с использованием встроенных методов Python или `collections`.\n",
    "2. **Для сложного текста и точности:** Использование `nltk` или алгоритмов поиска подстрок (KMP, Бойера-Мура).\n",
    "3. **Для масштабируемости и гибкости анализа:** Использование `pandas` или структур данных, таких как Trie.\n",
    "4. **Для контекстного поиска:** Применение языковых моделей.\n",
    "\n",
    "Выбор зависит от конкретных требований к задаче, объема текста и уровня требуемой точности и эффективности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb164e-241e-4ab9-bd70-cca2a4666691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
